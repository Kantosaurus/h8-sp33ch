{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28fcb69",
   "metadata": {},
   "source": [
    "# Base Models\n",
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a7ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class AdaBoostModel:\n",
    "    \"\"\"\n",
    "    AdaBoost model for hate speech classification\n",
    "    Adaptive Boosting with decision tree base estimators\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        # Create base estimator (decision tree)\n",
    "        base_estimator = DecisionTreeClassifier(\n",
    "            max_depth=3,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        self.model = AdaBoostClassifier(\n",
    "            estimator=base_estimator,\n",
    "            n_estimators=100,\n",
    "            learning_rate=1.0,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Train the AdaBoost model with cross-validation\n",
    "        \"\"\"\n",
    "        print(\"Training AdaBoost...\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"AdaBoost CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"AdaBoost Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = self.model.feature_importances_\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance\n",
    "    \n",
    "    def get_estimator_weights(self):\n",
    "        \"\"\"\n",
    "        Get weights of individual estimators\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting estimator weights\")\n",
    "        \n",
    "        return self.model.estimator_weights_\n",
    "    \n",
    "    def get_estimator_errors(self):\n",
    "        \"\"\"\n",
    "        Get errors of individual estimators\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting estimator errors\")\n",
    "        \n",
    "        return self.model.estimator_errors_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b473ab",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79182dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BaggingClassifierModel:\n",
    "    \"\"\"\n",
    "    Bagging Classifier model for hate speech classification\n",
    "    Combines multiple base estimators with bootstrap sampling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        base_estimator = DecisionTreeClassifier(\n",
    "            random_state=random_state,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2\n",
    "        )\n",
    "        \n",
    "        self.model = BaggingClassifier(\n",
    "            base_estimator=base_estimator,\n",
    "            n_estimators=10,\n",
    "            max_samples=1.0,\n",
    "            max_features=1.0,\n",
    "            bootstrap=True,\n",
    "            bootstrap_features=False,\n",
    "            oob_score=False,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        self.best_params = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5, tune_hyperparameters=True):\n",
    "        \"\"\"\n",
    "        Train the Bagging Classifier model with optional hyperparameter tuning\n",
    "        \"\"\"\n",
    "        print(\"Training Bagging Classifier...\")\n",
    "        \n",
    "        if tune_hyperparameters:\n",
    "            # Hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'n_estimators': [5, 10, 15, 20],\n",
    "                'max_samples': [0.7, 0.8, 0.9, 1.0],\n",
    "                'max_features': [0.7, 0.8, 0.9, 1.0],\n",
    "                'base_estimator__max_depth': [5, 10, 15],\n",
    "                'base_estimator__min_samples_split': [2, 5, 10]\n",
    "            }\n",
    "            \n",
    "            base_estimator = DecisionTreeClassifier(random_state=42)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                BaggingClassifier(\n",
    "                    base_estimator=base_estimator,\n",
    "                    bootstrap=True,\n",
    "                    bootstrap_features=False,\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                ),\n",
    "                param_grid,\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='f1',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            self.best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Bagging Classifier CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Bagging Classifier Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance (average across all estimators)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        # Average feature importance across all estimators\n",
    "        all_importances = []\n",
    "        for estimator in self.model.estimators_:\n",
    "            if hasattr(estimator, 'feature_importances_'):\n",
    "                all_importances.append(estimator.feature_importances_)\n",
    "        \n",
    "        if all_importances:\n",
    "            avg_importance = np.mean(all_importances, axis=0)\n",
    "        else:\n",
    "            avg_importance = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': avg_importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return avg_importance\n",
    "    \n",
    "    def get_estimator_predictions(self, X):\n",
    "        \"\"\"\n",
    "        Get predictions from individual estimators\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting estimator predictions\")\n",
    "        \n",
    "        predictions = []\n",
    "        for estimator in self.model.estimators_:\n",
    "            pred = estimator.predict(X)\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def get_estimator_probabilities(self, X):\n",
    "        \"\"\"\n",
    "        Get probability predictions from individual estimators\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting estimator probabilities\")\n",
    "        \n",
    "        probabilities = []\n",
    "        for estimator in self.model.estimators_:\n",
    "            if hasattr(estimator, 'predict_proba'):\n",
    "                prob = estimator.predict_proba(X)[:, 1]  # Probability of positive class\n",
    "                probabilities.append(prob)\n",
    "        \n",
    "        return np.array(probabilities)\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"\n",
    "        Get detailed model information\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting model info\")\n",
    "        \n",
    "        return {\n",
    "            'n_estimators': self.model.n_estimators,\n",
    "            'max_samples': self.model.max_samples,\n",
    "            'max_features': self.model.max_features,\n",
    "            'bootstrap': self.model.bootstrap,\n",
    "            'bootstrap_features': self.model.bootstrap_features,\n",
    "            'oob_score': self.model.oob_score,\n",
    "            'base_estimator_type': type(self.model.base_estimator).__name__,\n",
    "            'best_params': self.best_params\n",
    "        }\n",
    "    \n",
    "    def get_estimator_variance(self, X):\n",
    "        \"\"\"\n",
    "        Get variance of predictions across estimators (measure of uncertainty)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting estimator variance\")\n",
    "        \n",
    "        predictions = self.get_estimator_predictions(X)\n",
    "        variance = np.var(predictions, axis=0)\n",
    "        return variance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236750d8",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c0f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class XGBoostModel:\n",
    "    \"\"\"\n",
    "    XGBoost model for hate speech classification\n",
    "    Gradient Boosting with use_label_encoder=False\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=random_state,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Train the XGBoost model with cross-validation\n",
    "        \"\"\"\n",
    "        print(\"Training XGBoost...\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"XGBoost CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"XGBoost Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = self.model.feature_importances_\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66302f9b",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f92095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DecisionTreeModel:\n",
    "    \"\"\"\n",
    "    Decision Tree model for hate speech classification\n",
    "    Good for interpretability and handling non-linear relationships\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = DecisionTreeClassifier(\n",
    "            random_state=random_state,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            criterion='gini'\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        self.best_params = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5, tune_hyperparameters=True):\n",
    "        \"\"\"\n",
    "        Train the decision tree model with optional hyperparameter tuning\n",
    "        \"\"\"\n",
    "        print(\"Training Decision Tree...\")\n",
    "        \n",
    "        if tune_hyperparameters:\n",
    "            # Hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'max_depth': [5, 10, 15, 20, None],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'criterion': ['gini', 'entropy']\n",
    "            }\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                DecisionTreeClassifier(random_state=42),\n",
    "                param_grid,\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='f1',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            self.best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Decision Tree CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Decision Tree Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = self.model.feature_importances_\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance\n",
    "    \n",
    "    def get_tree_depth(self):\n",
    "        \"\"\"\n",
    "        Get the depth of the trained tree\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting tree depth\")\n",
    "        return self.model.get_depth() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bf577",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ElasticNetModel:\n",
    "    \"\"\"\n",
    "    Elastic Net model for hate speech classification\n",
    "    Combines L1 (Lasso) and L2 (Ridge) regularization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = LogisticRegression(\n",
    "            random_state=random_state,\n",
    "            penalty='elasticnet',  # Elastic Net regularization\n",
    "            solver='saga',\n",
    "            C=1.0,  # Inverse of regularization strength\n",
    "            l1_ratio=0.5,  # Mixing parameter (0=Ridge, 1=Lasso)\n",
    "            max_iter=1000\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        self.best_params = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5, tune_hyperparameters=True):\n",
    "        \"\"\"\n",
    "        Train the Elastic Net model with optional hyperparameter tuning\n",
    "        \"\"\"\n",
    "        print(\"Training Elastic Net...\")\n",
    "        \n",
    "        # Scale features for Elastic Net\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        if tune_hyperparameters:\n",
    "            # Hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'C': [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "                'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "                'max_iter': [1000, 2000]\n",
    "            }\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                LogisticRegression(\n",
    "                    random_state=42,\n",
    "                    penalty='elasticnet',\n",
    "                    solver='saga'\n",
    "                ),\n",
    "                param_grid,\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='f1',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            self.best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Elastic Net CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X_scaled)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Elastic Net Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance (coefficients)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = np.abs(self.model.coef_[0])\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance\n",
    "    \n",
    "    def get_regularization_info(self):\n",
    "        \"\"\"\n",
    "        Get information about regularization parameters\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting regularization info\")\n",
    "        \n",
    "        coefficients = self.model.coef_[0]\n",
    "        n_features = len(coefficients)\n",
    "        n_nonzero = np.count_nonzero(coefficients)\n",
    "        sparsity_ratio = 1 - (n_nonzero / n_features)\n",
    "        \n",
    "        return {\n",
    "            'C': self.model.C,\n",
    "            'l1_ratio': self.model.l1_ratio,\n",
    "            'total_features': n_features,\n",
    "            'non_zero_features': n_nonzero,\n",
    "            'zero_features': n_features - n_nonzero,\n",
    "            'sparsity_ratio': sparsity_ratio,\n",
    "            'l1_contribution': self.model.l1_ratio,\n",
    "            'l2_contribution': 1 - self.model.l1_ratio\n",
    "        }\n",
    "    \n",
    "    def get_selected_features(self, feature_names=None, threshold=0.0):\n",
    "        \"\"\"\n",
    "        Get features selected by Elastic Net (non-zero coefficients)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting selected features\")\n",
    "        \n",
    "        coefficients = self.model.coef_[0]\n",
    "        selected_indices = np.where(np.abs(coefficients) > threshold)[0]\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            selected_features = [feature_names[i] for i in selected_indices]\n",
    "            selected_coefficients = coefficients[selected_indices]\n",
    "            \n",
    "            selected_df = pd.DataFrame({\n",
    "                'feature': selected_features,\n",
    "                'coefficient': selected_coefficients,\n",
    "                'abs_coefficient': np.abs(selected_coefficients)\n",
    "            }).sort_values('abs_coefficient', ascending=False)\n",
    "            \n",
    "            return selected_df\n",
    "        else:\n",
    "            return {\n",
    "                'indices': selected_indices,\n",
    "                'coefficients': coefficients[selected_indices]\n",
    "            }\n",
    "    \n",
    "    def get_model_params(self):\n",
    "        \"\"\"\n",
    "        Get current model parameters\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'C': self.model.C,\n",
    "            'l1_ratio': self.model.l1_ratio,\n",
    "            'penalty': self.model.penalty,\n",
    "            'solver': self.model.solver,\n",
    "            'max_iter': self.model.max_iter,\n",
    "            'best_params': self.best_params\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d509769",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ExtraTreesModel:\n",
    "    \"\"\"\n",
    "    Extra Trees Classifier for hate speech classification\n",
    "    Introduces more randomness\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = ExtraTreesClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features='sqrt',\n",
    "            bootstrap=False,  # Extra Trees doesn't use bootstrap\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Train the Extra Trees model with cross-validation\n",
    "        \"\"\"\n",
    "        print(\"Training Extra Trees...\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Extra Trees CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Extra Trees Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = self.model.feature_importances_\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb32db3",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class GradientBoostingModel:\n",
    "    \"\"\"\n",
    "    Gradient Boosting model for hate speech classification\n",
    "    Excellent performance with sequential weak learners\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = GradientBoostingClassifier(\n",
    "            random_state=random_state,\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=3,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            subsample=1.0\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        self.best_params = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5, tune_hyperparameters=True):\n",
    "        \"\"\"\n",
    "        Train the gradient boosting model with optional hyperparameter tuning\n",
    "        \"\"\"\n",
    "        print(\"Training Gradient Boosting...\")\n",
    "        \n",
    "        if tune_hyperparameters:\n",
    "            # Hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.05, 0.1, 0.15],\n",
    "                'max_depth': [3, 5, 7],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'subsample': [0.8, 0.9, 1.0]\n",
    "            }\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                GradientBoostingClassifier(random_state=42),\n",
    "                param_grid,\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='f1',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            self.best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Gradient Boosting CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Gradient Boosting Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = self.model.feature_importances_\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance\n",
    "    \n",
    "    def get_staged_predictions(self, X, n_stages=None):\n",
    "        \"\"\"\n",
    "        Get predictions from each stage of the boosting process\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting staged predictions\")\n",
    "        \n",
    "        if n_stages is None:\n",
    "            n_stages = self.model.n_estimators\n",
    "        \n",
    "        staged_preds = []\n",
    "        for pred in self.model.staged_predict(X):\n",
    "            staged_preds.append(pred)\n",
    "            if len(staged_preds) >= n_stages:\n",
    "                break\n",
    "        \n",
    "        return np.array(staged_preds)\n",
    "    \n",
    "    def get_staged_probabilities(self, X, n_stages=None):\n",
    "        \"\"\"\n",
    "        Get probability predictions from each stage of the boosting process\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting staged probabilities\")\n",
    "        \n",
    "        if n_stages is None:\n",
    "            n_stages = self.model.n_estimators\n",
    "        \n",
    "        staged_probs = []\n",
    "        for prob in self.model.staged_predict_proba(X):\n",
    "            staged_probs.append(prob[:, 1])  # Probability of positive class\n",
    "            if len(staged_probs) >= n_stages:\n",
    "                break\n",
    "        \n",
    "        return np.array(staged_probs)\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"\n",
    "        Get detailed model information\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting model info\")\n",
    "        \n",
    "        return {\n",
    "            'n_estimators': self.model.n_estimators,\n",
    "            'learning_rate': self.model.learning_rate,\n",
    "            'max_depth': self.model.max_depth,\n",
    "            'min_samples_split': self.model.min_samples_split,\n",
    "            'min_samples_leaf': self.model.min_samples_leaf,\n",
    "            'subsample': self.model.subsample,\n",
    "            'best_params': self.best_params\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98887986",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f721f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class KNNModel:\n",
    "    \"\"\"\n",
    "    K-Nearest Neighbors model for hate speech classification\n",
    "    Good for capturing local patterns and non-linear decision boundaries\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = KNeighborsClassifier(\n",
    "            n_neighbors=5,\n",
    "            weights='uniform',\n",
    "            algorithm='auto',\n",
    "            leaf_size=30,\n",
    "            p=2  # Euclidean distance\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        self.best_params = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5, tune_hyperparameters=False):\n",
    "        \"\"\"\n",
    "        Train the KNN model with optional hyperparameter tuning\n",
    "        \"\"\"\n",
    "        print(\"Training K-Nearest Neighbors...\")\n",
    "        \n",
    "        # Scale features for KNN (important for distance-based algorithms)\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        if tune_hyperparameters:\n",
    "            # Hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'p': [1, 2],  # Manhattan and Euclidean distance\n",
    "                'leaf_size': [20, 30, 40]\n",
    "            }\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                KNeighborsClassifier(),\n",
    "                param_grid,\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='f1',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            self.best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"KNN CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X_scaled)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"KNN Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_neighbors_info(self, X, k=5):\n",
    "        \"\"\"\n",
    "        Get information about k nearest neighbors for given samples\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting neighbors info\")\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        distances, indices = self.model.kneighbors(X_scaled, n_neighbors=k)\n",
    "        \n",
    "        return {\n",
    "            'distances': distances,\n",
    "            'indices': indices\n",
    "        }\n",
    "    \n",
    "    def get_model_params(self):\n",
    "        \"\"\"\n",
    "        Get current model parameters\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'n_neighbors': self.model.n_neighbors,\n",
    "            'weights': self.model.weights,\n",
    "            'algorithm': self.model.algorithm,\n",
    "            'leaf_size': self.model.leaf_size,\n",
    "            'p': self.model.p\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac5097b",
   "metadata": {},
   "source": [
    "### Lasso Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d637d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class LassoClassifierModel:\n",
    "    \"\"\"\n",
    "    Lasso Classifier model for hate speech classification\n",
    "    Uses L1 regularization for feature selection and sparse solutions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = LogisticRegression(\n",
    "            random_state=random_state,\n",
    "            penalty='l1',  # Lasso regularization\n",
    "            solver='liblinear',\n",
    "            C=1.0,  # Inverse of regularization strength\n",
    "            max_iter=1000\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        self.best_params = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5, tune_hyperparameters=True):\n",
    "        \"\"\"\n",
    "        Train the Lasso Classifier model with optional hyperparameter tuning\n",
    "        \"\"\"\n",
    "        print(\"Training Lasso Classifier...\")\n",
    "        \n",
    "        # Scale features for Lasso\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        if tune_hyperparameters:\n",
    "            # Hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'C': [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                'max_iter': [1000, 2000]\n",
    "            }\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                LogisticRegression(\n",
    "                    random_state=42,\n",
    "                    penalty='l1',\n",
    "                    solver='liblinear'\n",
    "                ),\n",
    "                param_grid,\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='f1',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            self.best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Lasso Classifier CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X_scaled)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Lasso Classifier Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance (coefficients)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = np.abs(self.model.coef_[0])\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance\n",
    "    \n",
    "    def get_selected_features(self, feature_names=None, threshold=0.0):\n",
    "        \"\"\"\n",
    "        Get features selected by Lasso (non-zero coefficients)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting selected features\")\n",
    "        \n",
    "        coefficients = self.model.coef_[0]\n",
    "        selected_indices = np.where(np.abs(coefficients) > threshold)[0]\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            selected_features = [feature_names[i] for i in selected_indices]\n",
    "            selected_coefficients = coefficients[selected_indices]\n",
    "            \n",
    "            selected_df = pd.DataFrame({\n",
    "                'feature': selected_features,\n",
    "                'coefficient': selected_coefficients,\n",
    "                'abs_coefficient': np.abs(selected_coefficients)\n",
    "            }).sort_values('abs_coefficient', ascending=False)\n",
    "            \n",
    "            return selected_df\n",
    "        else:\n",
    "            return {\n",
    "                'indices': selected_indices,\n",
    "                'coefficients': coefficients[selected_indices]\n",
    "            }\n",
    "    \n",
    "    def get_sparsity_info(self):\n",
    "        \"\"\"\n",
    "        Get information about model sparsity\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting sparsity info\")\n",
    "        \n",
    "        coefficients = self.model.coef_[0]\n",
    "        n_features = len(coefficients)\n",
    "        n_nonzero = np.count_nonzero(coefficients)\n",
    "        sparsity_ratio = 1 - (n_nonzero / n_features)\n",
    "        \n",
    "        return {\n",
    "            'total_features': n_features,\n",
    "            'non_zero_features': n_nonzero,\n",
    "            'zero_features': n_features - n_nonzero,\n",
    "            'sparsity_ratio': sparsity_ratio\n",
    "        }\n",
    "    \n",
    "    def get_model_params(self):\n",
    "        \"\"\"\n",
    "        Get current model parameters\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'C': self.model.C,\n",
    "            'penalty': self.model.penalty,\n",
    "            'solver': self.model.solver,\n",
    "            'max_iter': self.model.max_iter,\n",
    "            'best_params': self.best_params\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c4253",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de17884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class LightGBMModel:\n",
    "    \"\"\"\n",
    "    LightGBM model for hate speech classification\n",
    "    Fast gradient boosting with leaf-wise tree growth\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = LGBMClassifier(\n",
    "            random_state=random_state,\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            num_leaves=31,\n",
    "            min_child_samples=20,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.0,\n",
    "            reg_lambda=0.0,\n",
    "            verbose=-1\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        self.best_params = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5, tune_hyperparameters=True):\n",
    "        \"\"\"\n",
    "        Train the LightGBM model with optional hyperparameter tuning\n",
    "        \"\"\"\n",
    "        print(\"Training LightGBM...\")\n",
    "        \n",
    "        if tune_hyperparameters:\n",
    "            # Hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.05, 0.1, 0.15],\n",
    "                'max_depth': [4, 6, 8],\n",
    "                'num_leaves': [15, 31, 63],\n",
    "                'min_child_samples': [10, 20, 30],\n",
    "                'subsample': [0.7, 0.8, 0.9],\n",
    "                'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "            }\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                LGBMClassifier(random_state=42, verbose=-1),\n",
    "                param_grid,\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='f1',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            self.best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"LightGBM CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"LightGBM Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None, importance_type='gain'):\n",
    "        \"\"\"\n",
    "        Get feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = self.model.feature_importances_\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance\n",
    "    \n",
    "    def get_feature_importance_split(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance based on split count\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = self.model.feature_importances_(importance_type='split')\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'split_importance': importance\n",
    "            }).sort_values('split_importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"\n",
    "        Get detailed model information\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting model info\")\n",
    "        \n",
    "        return {\n",
    "            'n_estimators': self.model.n_estimators,\n",
    "            'learning_rate': self.model.learning_rate,\n",
    "            'max_depth': self.model.max_depth,\n",
    "            'num_leaves': self.model.num_leaves,\n",
    "            'min_child_samples': self.model.min_child_samples,\n",
    "            'subsample': self.model.subsample,\n",
    "            'colsample_bytree': self.model.colsample_bytree,\n",
    "            'reg_alpha': self.model.reg_alpha,\n",
    "            'reg_lambda': self.model.reg_lambda,\n",
    "            'best_params': self.best_params\n",
    "        }\n",
    "    \n",
    "    def get_booster_info(self):\n",
    "        \"\"\"\n",
    "        Get information about the underlying booster\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting booster info\")\n",
    "        \n",
    "        booster = self.model.booster_\n",
    "        return {\n",
    "            'num_trees': booster.num_trees(),\n",
    "            'num_features': booster.num_features(),\n",
    "            'num_classes': booster.num_classes()\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb8ae62",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c29f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class LinearSVCModel:\n",
    "    \"\"\"\n",
    "    Linear Support Vector Classifier model for hate speech classification\n",
    "    Good for high-dimensional data and linear separability\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.base_model = LinearSVC(\n",
    "            random_state=random_state,\n",
    "            C=1.0,\n",
    "            loss='squared_hinge',\n",
    "            max_iter=1000,\n",
    "            dual=True\n",
    "        )\n",
    "        # Calibrated classifier for probability estimates\n",
    "        self.model = CalibratedClassifierCV(\n",
    "            self.base_model,\n",
    "            cv=3,\n",
    "            method='sigmoid'\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        self.best_params = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5, tune_hyperparameters=True):\n",
    "        \"\"\"\n",
    "        Train the Linear SVC model with optional hyperparameter tuning\n",
    "        \"\"\"\n",
    "        print(\"Training Linear SVC...\")\n",
    "        \n",
    "        # Scale features for SVC\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        if tune_hyperparameters:\n",
    "            # Hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'base_estimator__C': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "                'base_estimator__loss': ['hinge', 'squared_hinge'],\n",
    "                'base_estimator__max_iter': [1000, 2000]\n",
    "            }\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                CalibratedClassifierCV(\n",
    "                    LinearSVC(random_state=42),\n",
    "                    cv=3,\n",
    "                    method='sigmoid'\n",
    "                ),\n",
    "                param_grid,\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='f1',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            self.best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Linear SVC CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X_scaled)\n",
    "    \n",
    "    def predict_decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Get decision function values (distance from hyperplane)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.decision_function(X_scaled)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Linear SVC Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance (coefficients)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        # Get coefficients from the base estimator\n",
    "        base_estimator = self.model.base_estimator_\n",
    "        importance = np.abs(base_estimator.coef_[0])\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance\n",
    "    \n",
    "    def get_support_vectors_info(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Get information about support vectors\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting support vectors info\")\n",
    "        \n",
    "        X_train_scaled = self.scaler.transform(X_train)\n",
    "        base_estimator = self.model.base_estimator_\n",
    "        \n",
    "        # Get support vector indices\n",
    "        support_indices = base_estimator.support_\n",
    "        support_vectors = X_train_scaled[support_indices]\n",
    "        \n",
    "        return {\n",
    "            'n_support_vectors': len(support_indices),\n",
    "            'support_indices': support_indices,\n",
    "            'support_vectors': support_vectors,\n",
    "            'support_labels': y_train[support_indices]\n",
    "        }\n",
    "    \n",
    "    def get_model_params(self):\n",
    "        \"\"\"\n",
    "        Get current model parameters\n",
    "        \"\"\"\n",
    "        base_estimator = self.model.base_estimator_\n",
    "        return {\n",
    "            'C': base_estimator.C,\n",
    "            'loss': base_estimator.loss,\n",
    "            'max_iter': base_estimator.max_iter,\n",
    "            'dual': base_estimator.dual,\n",
    "            'best_params': self.best_params\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cdffa",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef46a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class LogisticRegressionModel:\n",
    "    \"\"\"\n",
    "    Logistic Regression model for hate speech classification\n",
    "    High bias, good baseline model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = LogisticRegression(\n",
    "            random_state=random_state,\n",
    "            max_iter=1000,\n",
    "            C=1.0,\n",
    "            solver='liblinear'\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Train the logistic regression model with cross-validation\n",
    "        \"\"\"\n",
    "        print(\"Training Logistic Regression...\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Logistic Regression CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Logistic Regression Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance (coefficients)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = np.abs(self.model.coef_[0])\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25ff10",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee763776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class NaiveBayesModel:\n",
    "    \"\"\"\n",
    "    Naive Bayes model for hate speech classification\n",
    "    Complements well with sparse data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = MultinomialNB(\n",
    "            alpha=1.0,\n",
    "            fit_prior=True,\n",
    "            class_prior=None\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Train the Naive Bayes model with cross-validation\n",
    "        \"\"\"\n",
    "        print(\"Training Naive Bayes...\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Naive Bayes CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Naive Bayes Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance (log probabilities)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        # For Naive Bayes, we can use the log probabilities as feature importance\n",
    "        # This shows which features contribute most to the classification\n",
    "        importance = np.abs(self.model.feature_log_prob_[1] - self.model.feature_log_prob_[0])\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96a487",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RandomForestModel:\n",
    "    \"\"\"\n",
    "    Random Forest model for hate speech classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features='sqrt',\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Train the Random Forest model with cross-validation\n",
    "        \"\"\"\n",
    "        print(\"Training Random Forest...\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Random Forest CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Random Forest Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = self.model.feature_importances_\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1430781",
   "metadata": {},
   "source": [
    "### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78335d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RidgeClassifierModel:\n",
    "    \"\"\"\n",
    "    Ridge Classifier model for hate speech classification\n",
    "    Good for high-dimensional data with L2 regularization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.base_model = RidgeClassifier(\n",
    "            random_state=random_state,\n",
    "            alpha=1.0,\n",
    "            solver='auto',\n",
    "            max_iter=1000\n",
    "        )\n",
    "        # Calibrated classifier for probability estimates\n",
    "        self.model = CalibratedClassifierCV(\n",
    "            self.base_model,\n",
    "            cv=3,\n",
    "            method='sigmoid'\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        self.best_params = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5, tune_hyperparameters=True):\n",
    "        \"\"\"\n",
    "        Train the Ridge Classifier model with optional hyperparameter tuning\n",
    "        \"\"\"\n",
    "        print(\"Training Ridge Classifier...\")\n",
    "        \n",
    "        # Scale features for Ridge Classifier\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        if tune_hyperparameters:\n",
    "            # Hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'base_estimator__alpha': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "                'base_estimator__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "            }\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                CalibratedClassifierCV(\n",
    "                    RidgeClassifier(random_state=42),\n",
    "                    cv=3,\n",
    "                    method='sigmoid'\n",
    "                ),\n",
    "                param_grid,\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='f1',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            self.best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Ridge Classifier CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X_scaled)\n",
    "    \n",
    "    def predict_decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Get decision function values\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.decision_function(X_scaled)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Ridge Classifier Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance (coefficients)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        # Get coefficients from the base estimator\n",
    "        base_estimator = self.model.base_estimator_\n",
    "        importance = np.abs(base_estimator.coef_[0])\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance\n",
    "    \n",
    "    def get_model_params(self):\n",
    "        \"\"\"\n",
    "        Get current model parameters\n",
    "        \"\"\"\n",
    "        base_estimator = self.model.base_estimator_\n",
    "        return {\n",
    "            'alpha': base_estimator.alpha,\n",
    "            'solver': base_estimator.solver,\n",
    "            'max_iter': base_estimator.max_iter,\n",
    "            'best_params': self.best_params\n",
    "        }\n",
    "    \n",
    "    def get_intercept(self):\n",
    "        \"\"\"\n",
    "        Get model intercept\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting intercept\")\n",
    "        return self.model.base_estimator_.intercept_[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f1d25",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SVMModel:\n",
    "    \"\"\"\n",
    "    Support Vector Machine with linear kernel for hate speech classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = LinearSVC(\n",
    "            random_state=random_state,\n",
    "            max_iter=1000,\n",
    "            C=1.0,\n",
    "            loss='squared_hinge'\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Train the SVM model with cross-validation\n",
    "        \"\"\"\n",
    "        print(\"Training SVM (LinearSVC)...\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"SVM CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities using decision function\n",
    "        Note: LinearSVC doesn't have predict_proba, so we use decision_function\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        \n",
    "        # Get decision function scores\n",
    "        decision_scores = self.model.decision_function(X)\n",
    "        \n",
    "        # Convert to probabilities using sigmoid-like transformation\n",
    "        # This is an approximation since LinearSVC doesn't provide probabilities\n",
    "        proba = 1 / (1 + np.exp(-decision_scores))\n",
    "        \n",
    "        # Return as 2D array [prob_class_0, prob_class_1]\n",
    "        return np.column_stack([1 - proba, proba])\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Get raw decision function scores\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.decision_function(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"SVM Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance (coefficients)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = np.abs(self.model.coef_[0])\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd4e2a",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f1ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class XGBoostModel:\n",
    "    \"\"\"\n",
    "    XGBoost model for hate speech classification\n",
    "    Gradient Boosting with use_label_encoder=False\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.model = xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=random_state,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Train the XGBoost model with cross-validation\n",
    "        \"\"\"\n",
    "        print(\"Training XGBoost...\")\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"XGBoost CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"XGBoost Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Get feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = self.model.feature_importances_\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            return importance_df\n",
    "        else:\n",
    "            return importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a2fcc",
   "metadata": {},
   "source": [
    "# Model Combination\n",
    "### Meta Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MetaClassifier:\n",
    "    \"\"\"\n",
    "    Meta-classifier that learns from base model outputs\n",
    "    Uses Logistic Regression to combine predictions with meta-features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.meta_model = LogisticRegression(\n",
    "            random_state=random_state,\n",
    "            max_iter=1000,\n",
    "            C=1.0,\n",
    "            solver='liblinear'\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_trained = False\n",
    "        self.base_models = {}\n",
    "        self.meta_features_names = []\n",
    "        \n",
    "    def add_base_model(self, name, model):\n",
    "        \"\"\"\n",
    "        Add a base model to the ensemble\n",
    "        \"\"\"\n",
    "        self.base_models[name] = model\n",
    "        \n",
    "    def extract_meta_features(self, X):\n",
    "        \"\"\"\n",
    "        Extract meta-features from base model predictions\n",
    "        \"\"\"\n",
    "        if not self.base_models:\n",
    "            raise ValueError(\"No base models added to meta-classifier\")\n",
    "        \n",
    "        meta_features = []\n",
    "        predictions = []\n",
    "        \n",
    "        # Get predictions from all base models\n",
    "        for name, model in self.base_models.items():\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                pred_proba = model.predict_proba(X)[:, 1]\n",
    "            elif hasattr(model, 'decision_function'):\n",
    "                pred_proba = model.decision_function(X)\n",
    "            else:\n",
    "                raise ValueError(f\"Model {name} must have predict_proba or decision_function method\")\n",
    "            \n",
    "            predictions.append(pred_proba)\n",
    "        \n",
    "        predictions = np.array(predictions).T  # Shape: (n_samples, n_models)\n",
    "        \n",
    "        # Meta-features:\n",
    "        # 1. Raw probabilities from each model\n",
    "        meta_features.append(predictions)\n",
    "        \n",
    "        # 2. Model disagreement (standard deviation of predictions)\n",
    "        disagreement = np.std(predictions, axis=1, keepdims=True)\n",
    "        meta_features.append(disagreement)\n",
    "        \n",
    "        # 3. Confidence gap (difference between max and min predictions)\n",
    "        confidence_gap = np.max(predictions, axis=1, keepdims=True) - np.min(predictions, axis=1, keepdims=True)\n",
    "        meta_features.append(confidence_gap)\n",
    "        \n",
    "        # 4. Prediction variance\n",
    "        prediction_variance = np.var(predictions, axis=1, keepdims=True)\n",
    "        meta_features.append(prediction_variance)\n",
    "        \n",
    "        # 5. Mean prediction\n",
    "        mean_prediction = np.mean(predictions, axis=1, keepdims=True)\n",
    "        meta_features.append(mean_prediction)\n",
    "        \n",
    "        # 6. Median prediction\n",
    "        median_prediction = np.median(predictions, axis=1, keepdims=True)\n",
    "        meta_features.append(median_prediction)\n",
    "        \n",
    "        # 7. Range of predictions\n",
    "        prediction_range = np.max(predictions, axis=1, keepdims=True) - np.min(predictions, axis=1, keepdims=True)\n",
    "        meta_features.append(prediction_range)\n",
    "        \n",
    "        # 8. Number of models predicting above threshold\n",
    "        threshold = 0.5\n",
    "        above_threshold = np.sum(predictions > threshold, axis=1, keepdims=True)\n",
    "        meta_features.append(above_threshold)\n",
    "        \n",
    "        # Combine all meta-features\n",
    "        combined_features = np.hstack(meta_features)\n",
    "        \n",
    "        # Store feature names for interpretability\n",
    "        if not self.meta_features_names:\n",
    "            self.meta_features_names = []\n",
    "            # Add base model prediction names\n",
    "            for name in self.base_models.keys():\n",
    "                self.meta_features_names.append(f\"{name}_pred\")\n",
    "            # Add meta-feature names\n",
    "            self.meta_features_names.extend([\n",
    "                'model_disagreement',\n",
    "                'confidence_gap',\n",
    "                'prediction_variance',\n",
    "                'mean_prediction',\n",
    "                'median_prediction',\n",
    "                'prediction_range',\n",
    "                'models_above_threshold'\n",
    "            ])\n",
    "        \n",
    "        return combined_features\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Train the meta-classifier on base model outputs\n",
    "        \"\"\"\n",
    "        print(\"Training Meta-Classifier...\")\n",
    "        \n",
    "        # Extract meta-features for training\n",
    "        X_meta_train = self.extract_meta_features(X_train)\n",
    "        \n",
    "        # Scale features\n",
    "        X_meta_train_scaled = self.scaler.fit_transform(X_meta_train)\n",
    "        \n",
    "        # Train meta-classifier\n",
    "        self.meta_model.fit(X_meta_train_scaled, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        # Evaluate on validation set if provided\n",
    "        if X_val is not None and y_val is not None:\n",
    "            X_meta_val = self.extract_meta_features(X_val)\n",
    "            X_meta_val_scaled = self.scaler.transform(X_meta_val)\n",
    "            \n",
    "            y_pred_meta = self.meta_model.predict(X_meta_val_scaled)\n",
    "            f1_meta = f1_score(y_val, y_pred_meta)\n",
    "            accuracy_meta = accuracy_score(y_val, y_pred_meta)\n",
    "            \n",
    "            print(f\"Meta-classifier validation F1: {f1_meta:.4f}\")\n",
    "            print(f\"Meta-classifier validation Accuracy: {accuracy_meta:.4f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using meta-classifier\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Meta-classifier must be trained before making predictions\")\n",
    "        \n",
    "        X_meta = self.extract_meta_features(X)\n",
    "        X_meta_scaled = self.scaler.transform(X_meta)\n",
    "        \n",
    "        return self.meta_model.predict(X_meta_scaled)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities from meta-classifier\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Meta-classifier must be trained before making predictions\")\n",
    "        \n",
    "        X_meta = self.extract_meta_features(X)\n",
    "        X_meta_scaled = self.scaler.transform(X_meta)\n",
    "        \n",
    "        return self.meta_model.predict_proba(X_meta_scaled)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate meta-classifier performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Meta-classifier must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Meta-Classifier Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Get meta-feature importance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Meta-classifier must be trained before getting feature importance\")\n",
    "        \n",
    "        importance = np.abs(self.meta_model.coef_[0])\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': self.meta_features_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    def get_base_model_predictions(self, X):\n",
    "        \"\"\"\n",
    "        Get predictions from all base models\n",
    "        \"\"\"\n",
    "        predictions = {}\n",
    "        \n",
    "        for name, model in self.base_models.items():\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                pred_proba = model.predict_proba(X)[:, 1]\n",
    "            elif hasattr(model, 'decision_function'):\n",
    "                pred_proba = model.decision_function(X)\n",
    "            else:\n",
    "                raise ValueError(f\"Model {name} must have predict_proba or decision_function method\")\n",
    "            \n",
    "            predictions[name] = pred_proba\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def analyze_model_agreement(self, X):\n",
    "        \"\"\"\n",
    "        Analyze agreement between base models\n",
    "        \"\"\"\n",
    "        predictions = self.get_base_model_predictions(X)\n",
    "        \n",
    "        # Convert to binary predictions\n",
    "        binary_predictions = {}\n",
    "        for name, pred in predictions.items():\n",
    "            binary_predictions[name] = (pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate agreement matrix\n",
    "        model_names = list(binary_predictions.keys())\n",
    "        n_models = len(model_names)\n",
    "        agreement_matrix = np.zeros((n_models, n_models))\n",
    "        \n",
    "        for i in range(n_models):\n",
    "            for j in range(n_models):\n",
    "                agreement = np.mean(binary_predictions[model_names[i]] == binary_predictions[model_names[j]])\n",
    "                agreement_matrix[i, j] = agreement\n",
    "        \n",
    "        return agreement_matrix, model_names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b37813",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class VotingClassifierModel:\n",
    "    \"\"\"\n",
    "    Voting Classifier model for hate speech classification\n",
    "    Combines multiple different base models with voting mechanism\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        # Define base estimators\n",
    "        estimators = [\n",
    "            ('lr', LogisticRegression(random_state=random_state, max_iter=1000)),\n",
    "            ('dt', DecisionTreeClassifier(random_state=random_state, max_depth=10)),\n",
    "            ('svc', SVC(random_state=random_state, probability=True)),\n",
    "            ('nb', MultinomialNB())\n",
    "        ]\n",
    "        \n",
    "        self.model = VotingClassifier(\n",
    "            estimators=estimators,\n",
    "            voting='soft',  # Use probability voting\n",
    "            weights=None  # Equal weights for all estimators\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_trained = False\n",
    "        self.cv_scores = None\n",
    "        \n",
    "    def train(self, X_train, y_train, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Train the Voting Classifier model\n",
    "        \"\"\"\n",
    "        print(\"Training Voting Classifier...\")\n",
    "        \n",
    "        # Scale features for models that need it\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=skf, scoring='f1')\n",
    "        \n",
    "        self.cv_scores = {\n",
    "            'f1_mean': cv_scores.mean(),\n",
    "            'f1_std': cv_scores.std(),\n",
    "            'f1_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        # Train on full dataset\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Voting Classifier CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return self.cv_scores\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction probabilities\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before making predictions\")\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X_scaled)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before evaluation\")\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        print(\"Voting Classifier Results:\")\n",
    "        for metric, value in results.items():\n",
    "            print(f\"  {metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_individual_predictions(self, X):\n",
    "        \"\"\"\n",
    "        Get predictions from individual estimators\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting individual predictions\")\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        predictions = {}\n",
    "        \n",
    "        for name, estimator in self.model.named_estimators_.items():\n",
    "            if hasattr(estimator, 'predict'):\n",
    "                pred = estimator.predict(X_scaled)\n",
    "                predictions[name] = pred\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def get_individual_probabilities(self, X):\n",
    "        \"\"\"\n",
    "        Get probability predictions from individual estimators\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting individual probabilities\")\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        probabilities = {}\n",
    "        \n",
    "        for name, estimator in self.model.named_estimators_.items():\n",
    "            if hasattr(estimator, 'predict_proba'):\n",
    "                prob = estimator.predict_proba(X_scaled)[:, 1]  # Probability of positive class\n",
    "                probabilities[name] = prob\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def get_estimator_weights(self):\n",
    "        \"\"\"\n",
    "        Get current estimator weights\n",
    "        \"\"\"\n",
    "        return self.model.weights\n",
    "    \n",
    "    def set_estimator_weights(self, weights):\n",
    "        \"\"\"\n",
    "        Set custom weights for estimators\n",
    "        \"\"\"\n",
    "        if len(weights) != len(self.model.estimators):\n",
    "            raise ValueError(f\"Number of weights ({len(weights)}) must match number of estimators ({len(self.model.estimators)})\")\n",
    "        \n",
    "        self.model.weights = weights\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"\n",
    "        Get detailed model information\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting model info\")\n",
    "        \n",
    "        estimator_info = []\n",
    "        for name, estimator in self.model.named_estimators_.items():\n",
    "            estimator_info.append({\n",
    "                'name': name,\n",
    "                'type': type(estimator).__name__,\n",
    "                'params': estimator.get_params()\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'voting': self.model.voting,\n",
    "            'weights': self.model.weights,\n",
    "            'estimators': estimator_info\n",
    "        }\n",
    "    \n",
    "    def get_consensus_analysis(self, X):\n",
    "        \"\"\"\n",
    "        Analyze consensus among individual estimators\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model must be trained before getting consensus analysis\")\n",
    "        \n",
    "        individual_preds = self.get_individual_predictions(X)\n",
    "        \n",
    "        # Convert to array for analysis\n",
    "        pred_array = np.array(list(individual_preds.values()))\n",
    "        \n",
    "        # Calculate consensus metrics\n",
    "        consensus_ratio = np.mean(pred_array, axis=0)  # Average prediction\n",
    "        agreement_count = np.sum(pred_array == pred_array[0], axis=0)  # Number of agreeing estimators\n",
    "        disagreement_ratio = 1 - (agreement_count / len(individual_preds))\n",
    "        \n",
    "        return {\n",
    "            'consensus_ratio': consensus_ratio,\n",
    "            'agreement_count': agreement_count,\n",
    "            'disagreement_ratio': disagreement_ratio,\n",
    "            'individual_predictions': individual_preds\n",
    "        } "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
